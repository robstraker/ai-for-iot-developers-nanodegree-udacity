#!/usr/bin/env python
# coding: utf-8

# # Exercise: FPGA and the DevCloud
# 
# The following are the tasks assigned to you for this exercise, 
# 
# 1. Load the license plate detection model on to the Intel Arria 10 FPGA and perform an inference on it.
# 2. Calculate the time it takes to do the Inference for 10 iterations

# <span class="graffiti-highlight graffiti-id_vskulnq-id_oudamc9"><i></i><button>Introduction</button></span>

# 
# 
# #### Set up paths so we can run Dev Cloud utilities
# You *must* run this every time they enter a Workspace session.

# In[ ]:


get_ipython().run_line_magic('env', 'PATH=/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/intel_devcloud_support')
import os
import sys
sys.path.insert(0, os.path.abspath('/opt/intel_devcloud_support'))
sys.path.insert(0, os.path.abspath('/opt/intel'))


# ## The model
# 
# We will be using the `vehicle-license-plate-detection-barrier-0106` model for this exercise. Remember that to run a model on the FPGA, we need to use FP16 as the model precision.
# 
# The model is present in the `/data/models/intel` folder.

# # Step 1: Creating a Python Script
# 
# The first step is to create a python script that you can use to load the model and perform an inference. I have used the `writefile` magic to create a python file called `inference_on_device.py`. You will need to complete this file.

# In[ ]:


get_ipython().run_cell_magic('writefile', 'inference_on_device.py', '\nimport time\nimport numpy as np\nimport cv2\nfrom openvino.inference_engine import IENetwork\nfrom openvino.inference_engine import IECore\nimport argparse\n\ndef main(args):\n    model=args.model_path\n    model_weights=model+\'.bin\'\n    model_structure=model+\'.xml\'\n    \n    start=time.time()\n    \n    # TODO: Load the model on VPU\n    \n    print(f"Time taken to load model = {time.time()-start} seconds")\n    \n    # Reading and Preprocessing Image\n    input_img=cv2.imread(\'car.png\')\n    input_img=cv2.resize(input_img, (300,300), interpolation = cv2.INTER_AREA)\n    input_img=np.moveaxis(input_img, -1, 0)\n\n    # TODO: Prepare the model for inference (create input dict etc.)\n    \n    start=time.time()\n    for _ in range(10):\n        # TODO: Run Inference in a Loop\n    \n    print(f"Time Taken to run 10 Inference on FPGA is = {time.time()-start} seconds")\n\nif __name__==\'__main__\':\n    parser=argparse.ArgumentParser()\n    parser.add_argument(\'--model_path\', required=True)\n    parser.add_argument(\'--device\', default=None)\n    \n    args=parser.parse_args() \n    main(args)')


# <span class="graffiti-highlight graffiti-id_f28ff2h-id_4psdryf"><i></i><button>Click here to Show the Solution for creating the python script</button></span>

# ## Step 2: Creating a job submission script
# 
# To submit a job to the devcloud, we need to create a script. I have named the script as `inference_fpga_model_job.sh`.
# 
# Can you write a script that will take the model path and device as a command line argument and then call the python file you created in the previous cell with the path to the model?
# 
# Remember that you will need to use the `aocl` command to load the bitstream file on to the FPGA

# In[ ]:


get_ipython().run_cell_magic('writefile', 'inference_fpga_model_job.sh', '\n#TODO: Create job submission script')


# <span class="graffiti-highlight graffiti-id_5e0vxvt-id_5zk2mzh"><i></i><button>Click here to Show the Solution for creating a job submission script</button></span>

# ## Step 3: Running on the FPGA
# 
# In the cell below, can you write the qsub command that will submit your job to the FPGA?

# In[ ]:


job_id_core = # TODO: Write qsub command
print(job_id_core[0])


# <span class="graffiti-highlight graffiti-id_yr40vov-id_cvo0xg6"><i></i><button>Click here to Show the Solution for submitting the job the FPGA</button></span>

# ## Step 4: Getting the Live Stat Values
# 
# By running the below command, we can see the live status of the commands.

# <span class="graffiti-highlight graffiti-id_ecvm8yr-id_nnpaoep"><i></i><button>Click here to know about liveqstat command</button></span>

# In[ ]:


import liveQStat
liveQStat.liveQStat()


# ## Step 5: Get the results
# 
# Running the cell below will get the output files from our job

# <span class="graffiti-highlight graffiti-id_s7wimuv-id_xm8qs9p"><i></i><button> Click here to know about fetching the output files containing the results</button></span>

# In[142]:


import get_results

get_results.getResults(job_id_core[0], filename="output.tgz", blocking=True)


# In[ ]:


get_ipython().system('tar zxf output.tgz')


# In[144]:


get_ipython().system('cat stdout.log')

