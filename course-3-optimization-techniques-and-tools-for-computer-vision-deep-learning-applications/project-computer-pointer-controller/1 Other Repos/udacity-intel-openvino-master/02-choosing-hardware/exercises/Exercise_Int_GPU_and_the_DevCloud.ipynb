{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution: Int GPU and the DevCloud\n",
    "\n",
    "This notebook contains the solution to the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Set up paths so we can run Dev Cloud utilities\n",
    "You *must* run this every time they enter a Workspace session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/intel_devcloud_support\n"
     ]
    }
   ],
   "source": [
    "%env PATH=/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/intel_devcloud_support\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel_devcloud_support'))\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "\n",
    "We will be using the `vehicle-license-plate-detection-barrier-0106` model for this exercise. Remember that to run a model on the GPU, we need to use FP16 as the model precision.\n",
    "\n",
    "The model is present in the `/data/models/intel` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Creating a Python Script\n",
    "\n",
    "The first step is to create a python script that you can use to load the model and perform an inference. This is my version of the python script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IENetwork\n",
    "from openvino.inference_engine import IECore\n",
    "import argparse\n",
    "\n",
    "def main(args):\n",
    "    model = args.model_path\n",
    "    model_weights = model + '.bin'\n",
    "    model_structure = model + '.xml'\n",
    "    \n",
    "    start = time.time()\n",
    "    print(\"Starting...\")\n",
    "    print(\"Device:\", args.device)\n",
    "    print(\"Model:\", args.model_path)\n",
    "\n",
    "    core = IECore()\n",
    "    print(\"Core created\")\n",
    "    \n",
    "    network = IENetwork(model_structure, model_weights)\n",
    "    print(\"Network created\")\n",
    "\n",
    "    exec_network = core.load_network(network, args.device, num_requests=1)\n",
    "    print(f\"Time taken to load model = {time.time()-start} seconds\")\n",
    "\n",
    "    # Reading and Preprocessing Image\n",
    "    input_img=cv2.imread('car.png')\n",
    "    input_img=cv2.resize(input_img, (300,300), interpolation = cv2.INTER_AREA)\n",
    "    input_img=np.moveaxis(input_img, -1, 0)\n",
    "    print(\"Image prepared\")\n",
    "\n",
    "    # Running Inference in a loop on the same image\n",
    "    input_key = next(iter(network.inputs))\n",
    "    input_dict = {input_key:input_img}\n",
    "    print(\"Input created\")\n",
    "\n",
    "    start=time.time()\n",
    "    for i in range(10):\n",
    "        exec_network.infer(input_dict)\n",
    "        print(f\"#{i} Inference completed\")\n",
    "    \n",
    "    print(f\"Time Taken to run 10 Inferences on {args.device} is: {time.time()-start} seconds\")\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_path', required=True)\n",
    "    parser.add_argument('--device', default=None)\n",
    "    \n",
    "    args=parser.parse_args() \n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Creating a job submission script\n",
    "\n",
    "To submit a job to the devcloud, we need to create a script. I have named the script as `inference_cpu_model_job.sh` and in the cell below, you can find my version of the finished script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference_job.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference_job.sh\n",
    "\n",
    "exec 1>/output/stdout.log 2>/output/stderr.log\n",
    "mkdir -p /output\n",
    "\n",
    "DEVICE=$1\n",
    "MODELPATH=$2\n",
    "\n",
    "# Run the load model python script\n",
    "python3 inference.py  --model_path ${MODELPATH} --device ${DEVICE}\n",
    "\n",
    "cd /output\n",
    "tar zcvf output.tgz stdout.log stderr.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Running on the CPU or GPU\n",
    "\n",
    "The cell below contains the command to submit jobs on the CPU or Int. GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J8zMylGtEmlZ8XaGTGEojSPpK4F4IPnq\n"
     ]
    }
   ],
   "source": [
    "DEVICE_CPU = 'CPU'\n",
    "DEVICE_GPU = 'GPU'\n",
    "MODEL_CPU = '/data/models/intel/vehicle-license-plate-detection-barrier-0106/FP32/vehicle-license-plate-detection-barrier-0106'\n",
    "MODEL_GPU = '/data/models/intel/vehicle-license-plate-detection-barrier-0106/FP16/vehicle-license-plate-detection-barrier-0106'\n",
    "NODE_CPU = 'tank-870:e3-1268l-v5'\n",
    "NODE_GPU = 's002-n011:i5-6500te:intel-hd-530'\n",
    "\n",
    "#job_id = !qsub inference_job.sh -d . -l nodes=1:{NODE_CPU} -F \"{DEVICE_CPU} {MODEL_CPU}\" -N store_core \n",
    "job_id = !qsub inference_job.sh -d . -l nodes=1:{NODE_GPU} -F \"{DEVICE_GPU} {MODEL_GPU}\" -N store_core\n",
    "        \n",
    "print(job_id[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Getting the Live Stat Values\n",
    "\n",
    "By running the below command, we can see the live status of the commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Polling statuses 6 more times. (Interrupt the kernel to stop)</p><ul><table style=\"width:100%\"><tr><th>JobID</th>\n",
       "      <th>Status</th>\n",
       "      <th>Desc</th>\n",
       "      </tr><tr style=\"color:black;font-weight:normal\"><td>0BfwOOVz0Jf2dnBKwu2Qd3ug1bCaKAgD</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>0hNjDLRw98A0nWls9YUI5JNIOt4bLv2D</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>1iVj41Xq7Hiv3LDPERYyRzHK01T3NDUO</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>3BGxpglWsmqchaJ4ICmkfRGCtfwaxLip</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>5mXalcpohn9Pqy24rcalRM7I6z3WGzjM</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>6eOtrXEBgqhcuDS9I2iQ1S3Jmn1Ux9Y4</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>B9y0ZRATf7o0Wm9kErqq0BInuLnv5lxV</td><td>Q</td><td>Job is queued, and is waiting for resources.</td><tr style=\"color:black;font-weight:normal\"><td>BEZrMcOksxU0Unkor34BMdp3G5eiLc1Z</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>EEF7ZlOZuBNBGCjnAdomLKN9WXdwQOlQ</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>gCNLTryVFr9d6tvOARRKtjYT28t05RRa</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>GSOO96DEfADbxdo9WLtdfb9HqdFjCoZt</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>gwSk0TWTKBS3Ut8O8G3LpywFDQJtPPBN</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>hruaRXeOc2LjNXVRGi1qqBNfsceFqU7Z</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>IYgIQDRA9n3nLwd6eK69ifQI70D5xcve</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>J8zMylGtEmlZ8XaGTGEojSPpK4F4IPnq</td><td>Q</td><td>Job is queued, and is waiting for resources.</td><tr style=\"color:black;font-weight:normal\"><td>jyFGk8JA1RmRMKtXp5sjq8K0ZdvkhqYm</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>LrrJL06NyulODJp6WbnsOuPzaIgMXXIp</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>Mao6URb6rBCzG8oojmCqRXnhheRPQLGN</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>NeS8IxzQJcpF2lHBPVh0SISreWfY0Oaj</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>qZeXbt7WN8210wsYU4UWIgVzJTaMEUkP</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>RdA9DhSadj0Z2tU37AfMaW04YKKN0u31</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>uzfhEitI5nFXHKA7hUV8tKCwIqZPiBH8</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>VeXaaTAKZFPjZgOPoOpelU1ezEde7jVS</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>W9zMEyLxEeTOEERfT7ISLTPAkrqhBMgJ</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>WllWVgc6l5dPl6TFc65dJm8QB9YxKIwy</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>wsj2c6Ee9Jr9BdhWTEzMNN6NEL0hNIej</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>XwPPySB69kxVvtf983nAZDKfO2ld9v18</td><td>W</td><td>Job is completed, but waiting on results.</td><tr style=\"color:black;font-weight:normal\"><td>yf22gWLZZveRiJBHcYfa8DK3vJBRdIRT</td><td>W</td><td>Job is completed, but waiting on results.</td></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import liveQStat\n",
    "liveQStat.liveQStat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Get the results\n",
    "\n",
    "Running the cell below will get the output files from our job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_results\n",
    "\n",
    "get_results.getResults(job_id[0], filename=\"output.tgz\", blocking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar zxf output.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat stdout.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
