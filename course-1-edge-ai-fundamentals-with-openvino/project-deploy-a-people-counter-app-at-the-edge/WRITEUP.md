# Deploy a People Counter App at the Edge: Project Write-Up
### Submitted by Rob Straker on Apr 24, 2020

In this project, I utilized the Intel® Distribution of the OpenVINO™ Toolkit to build a
People Counter app, including performing inference on an input video, extracting and
analyzing the output data, then sending that data to a server. The model was deployed on 
the edge, such that only data on 1) the number of people in the frame, 2) time those 
people spent in frame, and 3) the total number of people counted were sent to a MQTT 
server. Inference was done on my local machine.

## Explaining Custom Layers

A Supported Layer is any layer in one of the supported frameworks (e.g. TensorFlow, 
Caffe or ONNX) that can be directly converted by the Model Optimizer. If this cannot occur,
the layer is an Unsupported Layer. One potential solution is to run the Unsupported Layer
in its original framework. Another solution to deal with Unsupported Layers is to use 
Custom Layers. In fact, any layer not in the list of Supported Layers is automatically classified
by the Model Optimizer as a Custom Layer. 

Adding Custom Layers depends on the original model framework as follows:
- Option 1: For both TensorFlow and Caffe, the first option is to register the Custom 
Layers as extensions to the Model Optimizer.
- Option 2: For Caffe, the second option is to register the layers as Custom, then use
Caffe to calculate the output shape of the layer, but you'll need Caffe on your system.
- Option 2: For TensorFlow, the second option is to replace the unsupported subgraph with 
a different subgraph.
- Option 3: For TensoFlow, the third option is to offload the computation of the subgraph
back to TensorFlow during inference.

## Assessing Model Performance

I selected the ssd_mobilenet_v1_coco model for conversion to an Intermediate Representation 
format. The size of the model pre-conversion was 69.7MB (.pb file) and post-conversion it
was 67.4MB (.xml and .bin files). 

After completing the implementation of the main.py and inference.py files, I added 
additional processing of the output to handle incorrect detections, such as adjusting 
confidence threshold or accounting for 1-2 frames where the model fails to see a person 
already counted and would otherwise double count.

Key people counter app statistics included:
- Time to load the model = 0.3973s
- Inference time of the model = 190.7s

The model performance versus expectations was as follows:

People Detected	| Duration (s) | Actual Duration (s) | Average Duration (s)


| People Detected | Duration (s) | Average Duration (s) |
| :------------- |:------------:| --------------------:|
| 1               | 19.1         | 19.1                 |
| 2               | 31.2         | 25.3                 |
| 3               | 27.9         | 26.1                 |
| 4               | 51.0         | 33.6                 |
| 5               | 38.7         | 35.0                 |
| 6               | 18.5         | 32.4                 |

To achieve this performance, I set parameters as follows:
- confidence_threshold = 0.6
- ND_threshold = 2.0 (seconds)
- MV_threshold = 200 (pixels)

## Assess Model Use Cases

There are many potential use cases of the people counter app, including in the following
industries:
- Retail: Assessing footfall traffic in retail stores can help calculate traffic by time
or day of week, or by location within the store. This will help allocate staff, schedule
open/close hours, manage queues, and evaluate the effectiveness of specific displays.
- Manufacturing: Assessing location and movement of workers can help to improve warehouse
or plant layouts, manage queues on production and quality control lines, or identify
bottlenecks or production issues in real time.
- Hospitality: Assessing footfall and location of people in restaurants can help allocate
staff, schedule open/close hours, improve layout of tables and stations, and evaluate
profitability measures like length of stay and size of party.
- Transportation: Assessing footfall traffic on bus and subway platforms and in stations
can help allocate staff, schedule open/close hours, manage numbers of trains and buses,
improve platform and station layout, and identify issues in real time.

## Assess Effects on End User Needs

Lighting, model accuracy, and camera focal length/image size have different effects on a
deployed edge model. The potential effects of each of these are as follows:
- Lighting: Higher levels of light will correlate with higher accuracy of person detection,
whereas low light conditions will cause lower accuracy and higher error rates.
- Model Accuracy: The more accurate the model, the more accurate the results generated by
the deployed edge model. This can be the difference between results that are reasonable
and useful, to results that are too inaccurate to be depended on for decision-making.
- Camera Focal Length: The longer the camera focal length, the greater the field of 
focus, meaning that more people from shallow foreground to deep background can be accurately
identified and counted. A shorter focal length will reduce the number of people in a 
particular frame that can be accurately classified and counted.
- Camera Image Size: The larger the camera image created, the greater the amount of detail
that can be assessed by the people counter app, leading to greater accuracy of people
detection. A smaller camera image will cause worse detection and counting.

## Model Research

I selected the ssd_mobilenet_v1_coco model for two reasons. First, this was a familiar
model due to its use in the Model Optimizer lessons in Udacity's Intel Edge AI for IoT
Developers Nanodegree. Second, it is a Single-Shot multibox Detection (SSD) network 
intended to perform object detection, on not just faces, but on any kind of object.

Following are details of how I converted the model successfully:

- Model: ssd_mobilenet_v1_coco
- Model Source: https://github.com/opencv/open_model_zoo
- Model Conversion: I converted the model to an Intermediate Representation with the command
 "python/opt/intel/openvino/deployment_tools/model_optimizer/mo.py" with the arguments:
  	--input_model frozen_inference_graph.pb 
  	--tensorflow_object_detection_api_pipeline_config pipeline.config 
  	--reverse_input_channels 
  	--tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/
  	model_optimizer/extensions/front/tf/ssd_v2_support.json

