{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_vgn0tc0"
   },
   "source": [
    "# Exercise_Multi_Device_Plugin_and_the_DevCloud\n",
    "\n",
    "In this exercise, you will need to perform the following tasks\n",
    "1. Load the model on three types of devices\n",
    "    - CPU and VPU\n",
    "    - GPU and VPU\n",
    "    - CPU, GPU and VPU\n",
    "2. Note the time for inference for all three types of devices for 1000 iterations\n",
    "3. Plot the compare using graphs for the following\n",
    "  - Model Loading Time\n",
    "  - Inference Time\n",
    "  - Frames Per Second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_p44n0ti"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_p44n0ti-id_yda56u5\"><i></i><button>Introduction</button></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_emt69f7"
   },
   "source": [
    "\n",
    "\n",
    "#### Set up paths so we can run Dev Cloud utilities\n",
    "You *must* run this every time they enter a Workspace session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_ka475wk"
   },
   "outputs": [],
   "source": [
    "%env PATH=/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/intel_devcloud_support\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel_devcloud_support'))\n",
    "sys.path.insert(0, os.path.abspath('/opt/intel'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_8g77ids"
   },
   "source": [
    "## The model\n",
    "\n",
    "We will be using the `vehicle-license-plate-detection-barrier-0106` model for this exercise. Remember that to run a model on the GPU, we need to use FP16 as the model precision.\n",
    "\n",
    "The model is present in the `/data/models/intel` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_bvbdzt1"
   },
   "source": [
    "# Step 1: Creating a Python Script\n",
    "\n",
    "The first step is to create a python script that you can use to load the model and perform an inference. I have used the `writefile` magic to create a python file called `load_model_to_cpu.py`. You will need to complete this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_cu3pjsk"
   },
   "outputs": [],
   "source": [
    "%%writefile inference_on_device.py\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from openvino.inference_engine import IENetwork\n",
    "from openvino.inference_engine import IEPlugin\n",
    "import argparse\n",
    "\n",
    "def main(args):\n",
    "    model=args.model_path\n",
    "    model_weights=model+'.bin'\n",
    "    model_structure=model+'.xml'\n",
    "    \n",
    "    start=time.time()\n",
    "    \n",
    "    # TODO: Load the model\n",
    "    \n",
    "    print(f\"Time taken to load model = {time.time()-start} seconds\")\n",
    "    \n",
    "    # Reading and Preprocessing Image\n",
    "    input_img=cv2.imread('car.png')\n",
    "    input_img=cv2.resize(input_img, (300,300), interpolation = cv2.INTER_AREA)\n",
    "    input_img=np.moveaxis(input_img, -1, 0)\n",
    "\n",
    "    # TODO: Prepare the model for inference (create input dict etc.)\n",
    "    \n",
    "    start=time.time()\n",
    "    for _ in range(10):\n",
    "        # TODO: Run Inference in a Loop\n",
    "    \n",
    "    print(f\"Time Taken to run 100 inference is = {time.time()-start} seconds\")\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_path', required=True)\n",
    "    parser.add_argument('--device', default=None)\n",
    "    \n",
    "    args=parser.parse_args() \n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_56oyir6"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_56oyir6-id_e6u6ngz\"><i></i><button>Click here to Show the Solution of creation of a python script</button></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_wcotz2q"
   },
   "source": [
    "## Step 2: Creating a job submission script\n",
    "\n",
    "To submit a job to the devcloud, we need to create a script. I have named the script as `inference_gpu_model_job.sh`.\n",
    "\n",
    "Can you write a script that will take the model path and device as a command line argument and then call the python file you created in the previous cell with the path to the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_yc86wv4"
   },
   "outputs": [],
   "source": [
    "%%writefile inference_gpu_model_job.sh\n",
    "\n",
    "#TODO: Create job submission script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_7znu1gt"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_7znu1gt-id_97beuhh\"><i></i><button>Click here to Show the Solution to create a job submission script</button></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_i9w720t"
   },
   "source": [
    "## Step 3a: Running on the CPU and NCS2\n",
    "\n",
    "In the cell below, can you write the qsub command that will submit your job to the CPU and NCS2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_4x3ytxt"
   },
   "outputs": [],
   "source": [
    "job_id_core = # TODO: Write qsub command\n",
    "print(job_id_core[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_b84ire6"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_b84ire6-id_z26mkwx\"><i></i><button>Click here to Show the Solution to submit a job to CPU and the NCS2</button></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_i9w720t"
   },
   "source": [
    "## Step 3b: Running on the GPU and NCS2\n",
    "\n",
    "\n",
    "In the cell below, can you write the qsub command that will submit your job to the CPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_4x3ytxt"
   },
   "outputs": [],
   "source": [
    "job_id_core = # TODO: Write qsub command\n",
    "print(job_id_core[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_irlyopd"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_irlyopd-id_9nxj8l2\"><i></i><button>Click here to Show the Solution to submit a job to GPU and the NCS2</button></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_i9w720t"
   },
   "source": [
    "## Step 3c: Running on the CPU, GPU and NCS2\n",
    "\n",
    "In the cell below, can you write the qsub command that will submit your job to the CPU, GPU and NCS2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_4x3ytxt"
   },
   "outputs": [],
   "source": [
    "job_id_core = # TODO: Write qsub command\n",
    "print(job_id_core[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_npwrqhk"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_npwrqhk-id_29kz9m6\"><i></i><button>Click here to Show the Solution to submit a job to CPU, GPU and the NCS2</button></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_ez61vai"
   },
   "source": [
    "## Step 4: Getting the Live Stat Values\n",
    "\n",
    "By running the below command, we can see the live status of the commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_qq13jka"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_qq13jka-id_wdv5nio\"><i></i><button>Click here to check the submitted job status</button></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_qy4jbza"
   },
   "outputs": [],
   "source": [
    "import liveQStat\n",
    "liveQStat.liveQStat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_3hbdgnm"
   },
   "source": [
    "## Step 5: Get the results\n",
    "\n",
    "Running the cell below will get the output files from our job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_0h8h3y7"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_0h8h3y7-id_g09u1s8\"><i></i><button>Click here to know how fetch the results</button></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "graffitiCellId": "id_zj7u4dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getResults() is blocking until results of the job (id:wNQmOl57h5d4IqgJ9A6LiZTyMWDow20F) are ready.\n",
      "Please wait...Success!\n",
      "output.tgz was downloaded in the same folder as this notebook.\n"
     ]
    }
   ],
   "source": [
    "import get_results\n",
    "\n",
    "get_results.getResults(cpu_gpu_vpu_job_id_core[0], filename=\"output.tgz\", blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "graffitiCellId": "id_tc2hut8"
   },
   "outputs": [],
   "source": [
    "!tar zxf output.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "graffitiCellId": "id_xskw2sg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load model = 3.0154998302459717 seconds\r\n",
      "Time Taken to run 1000 Inference is = 3.4908461570739746 seconds\r\n",
      "cpu_vpu_stats.txt\r\n",
      "stderr.log\r\n"
     ]
    }
   ],
   "source": [
    "!cat stdout.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "graffitiCellId": "id_zj7u4dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getResults() is blocking until results of the job (id:Nl7NCiwxlV3OI0j9sOKCtUkhjc1kDPXU) are ready.\n",
      "Please wait...Success!\n",
      "output.tgz was downloaded in the same folder as this notebook.\n"
     ]
    }
   ],
   "source": [
    "import get_results\n",
    "\n",
    "get_results.getResults(cpu_gpu_vpu_job_id_core[0], filename=\"output.tgz\", blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "graffitiCellId": "id_tc2hut8"
   },
   "outputs": [],
   "source": [
    "!tar zxf output.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "graffitiCellId": "id_xskw2sg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load model = 27.72061538696289 seconds\r\n",
      "Time Taken to run 1000 Inference is = 5.869344234466553 seconds\r\n",
      "gpu_vpu_stats.txt\r\n",
      "stderr.log\r\n"
     ]
    }
   ],
   "source": [
    "!cat stdout.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_zj7u4dd"
   },
   "outputs": [],
   "source": [
    "import get_results\n",
    "\n",
    "get_results.getResults(cpu_gpu_vpu_job_id_core[0], filename=\"output.tgz\", blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "graffitiCellId": "id_tc2hut8"
   },
   "outputs": [],
   "source": [
    "!tar zxf output.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "graffitiCellId": "id_xskw2sg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load model = 28.09962511062622 seconds\r\n",
      "Time Taken to run 1000 Inference is = 3.519026279449463 seconds\r\n",
      "cpu_gpu_vpu_stats.txt\r\n",
      "stderr.log\r\n"
     ]
    }
   ],
   "source": [
    "!cat stdout.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_1nfn5gn"
   },
   "source": [
    "## Step 6: View the Outputs\n",
    "\n",
    "Can you plot the load time, inference time and the frames per second in the cell below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_6y1qs7w"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#File Paths to stats files\n",
    "paths=['gpu_stats.txt', 'cpu_stats.txt']\n",
    "\n",
    "# TODO: Plot the different stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "graffitiCellId": "id_7ibomgq"
   },
   "source": [
    "<span class=\"graffiti-highlight graffiti-id_7ibomgq-id_r5doaij\"><i></i><button>Click here to know how to plot and compare the results</button></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "graffitiCellId": "id_9li4yyw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "graffiti": {
   "firstAuthorId": "10505542082",
   "id": "id_5wv2x9f",
   "language": "EN"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
